{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# HF Transformers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "#Datahandeling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from datasets import load_metric,list_metrics\n",
    "import datetime\n",
    "\n",
    "# GPU Flushing\n",
    "import gc\n",
    "\n",
    "# Evaluation\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar  2 13:49:24 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 496.13       Driver Version: 496.13       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:25:00.0  On |                  N/A |\n",
      "| 29%   29C    P8     7W / 120W |   1677MiB /  3072MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       956    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      2640    C+G   ...\\app-1.0.9004\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A      3548    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A      3792    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      4468    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      6132    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9480    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     10948    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     11008    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11996    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     12792    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     14084      C   ...ython\\Python39\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     14464    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     15520    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     16004    C+G   ...zpdnekdrzrea0\\Spotify.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1060 3GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ds = datasets.load_from_disk(\"../data/processed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ARCHITECTURE = 'distilbert-base-uncased' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ARCHITECTURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_ARCHITECTURE, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "#1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9423, 0.2257, 0.8320], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class_weights = (1 - (df[\"class\"].value_counts().sort_index()/len(df))).values\n",
    "class_weights = torch.from_numpy(class_weights).float().to(\"cuda\")\n",
    "print(class_weights)\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss (suppose one has 3 labels with different weights)\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "#torch.tensor([2.0, 1.0, 1.0],device=torch.device(\"cuda:{}\".format(torch.cuda.current_device())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "100%|██████████| 155/155 [42:21<00:00, 16.40s/it]\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    accuracy = load_metric(\"accuracy\").compute(predictions=predictions, references=labels)\n",
    "    precision = load_metric(\"precision\").compute(predictions=predictions, references=labels,average=\"weighted\")\n",
    "    f1 = load_metric(\"f1\").compute(predictions=predictions, references=labels,average=\"weighted\")\n",
    "    recall = load_metric(\"recall\").compute(predictions=predictions, references=labels,average=\"weighted\")\n",
    "    return {\"accuracy\":accuracy, \"precision\":precision, \"recall\":recall, \"f1\":f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../results\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.001,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    resume_from_checkpoint = None,\n",
    "    logging_dir = \"../logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "    logging_steps = 100,\n",
    "    fp16 = False\n",
    "    #eval_steps = 500\n",
    ")\n",
    "\n",
    "#tb_callback = TrainerCallback()\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_test_ds[\"train\"],\n",
    "    eval_dataset=train_test_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    "#    callbacks = [tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tweet.\n",
      "***** Running training *****\n",
      "  Num examples = 22304\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4182\n",
      "  2%|▏         | 100/4182 [01:28<1:06:47,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0484, 'learning_rate': 9.760879961740794e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 200/4182 [03:09<25:35,  2.59it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0366, 'learning_rate': 9.521759923481588e-06, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 300/4182 [04:49<1:02:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0335, 'learning_rate': 9.282639885222381e-06, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 400/4182 [06:34<1:04:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0468, 'learning_rate': 9.043519846963177e-06, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 500/4182 [08:15<1:06:09,  1.08s/it]Saving model checkpoint to ../results\\checkpoint-500\n",
      "Configuration saved in ../results\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0324, 'learning_rate': 8.80439980870397e-06, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../results\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in ../results\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in ../results\\checkpoint-500\\special_tokens_map.json\n",
      " 14%|█▍        | 600/4182 [10:01<1:02:15,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0489, 'learning_rate': 8.565279770444764e-06, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 700/4182 [11:43<1:05:29,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0209, 'learning_rate': 8.326159732185559e-06, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 800/4182 [13:23<53:24,  1.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0151, 'learning_rate': 8.087039693926352e-06, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 900/4182 [14:58<53:13,  1.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0423, 'learning_rate': 7.847919655667146e-06, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1000/4182 [16:36<50:16,  1.05it/s] Saving model checkpoint to ../results\\checkpoint-1000\n",
      "Configuration saved in ../results\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0742, 'learning_rate': 7.608799617407939e-06, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../results\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in ../results\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in ../results\\checkpoint-1000\\special_tokens_map.json\n",
      " 26%|██▋       | 1100/4182 [18:13<48:40,  1.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0168, 'learning_rate': 7.369679579148733e-06, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 1200/4182 [19:48<47:08,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.05, 'learning_rate': 7.130559540889527e-06, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1300/4182 [21:23<45:36,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0653, 'learning_rate': 6.8914395026303206e-06, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1394/4182 [22:52<44:02,  1.06it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tweet.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2479\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9080274304154902}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9037245797016765}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9080274304154902}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9050928399319774}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                   \n",
      " 33%|███▎      | 1394/4182 [23:39<44:02,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0014368295669556, 'eval_accuracy': {'accuracy': 0.9080274304154902}, 'eval_precision': {'precision': 0.9037245797016765}, 'eval_recall': {'recall': 0.9080274304154902}, 'eval_f1': {'f1': 0.9050928399319774}, 'eval_runtime': 47.2325, 'eval_samples_per_second': 52.485, 'eval_steps_per_second': 3.282, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1400/4182 [23:45<2:34:12,  3.33s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0394, 'learning_rate': 6.652319464371115e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1500/4182 [25:20<42:25,  1.05it/s]  Saving model checkpoint to ../results\\checkpoint-1500\n",
      "Configuration saved in ../results\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0007, 'learning_rate': 6.413199426111909e-06, 'epoch': 1.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../results\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in ../results\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in ../results\\checkpoint-1500\\special_tokens_map.json\n",
      " 38%|███▊      | 1600/4182 [26:57<40:48,  1.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0138, 'learning_rate': 6.174079387852703e-06, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1700/4182 [28:32<39:17,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.032, 'learning_rate': 5.934959349593496e-06, 'epoch': 1.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1800/4182 [30:07<37:43,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.015, 'learning_rate': 5.695839311334291e-06, 'epoch': 1.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1900/4182 [31:42<36:15,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0083, 'learning_rate': 5.456719273075084e-06, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2000/4182 [33:17<34:25,  1.06it/s]Saving model checkpoint to ../results\\checkpoint-2000\n",
      "Configuration saved in ../results\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0299, 'learning_rate': 5.217599234815878e-06, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../results\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in ../results\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in ../results\\checkpoint-2000\\special_tokens_map.json\n",
      " 50%|█████     | 2100/4182 [34:54<32:50,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0111, 'learning_rate': 4.978479196556672e-06, 'epoch': 1.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2200/4182 [36:29<31:23,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0157, 'learning_rate': 4.7393591582974654e-06, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 2300/4182 [38:04<29:42,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0478, 'learning_rate': 4.50023912003826e-06, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 2400/4182 [39:38<28:11,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0119, 'learning_rate': 4.261119081779053e-06, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 2500/4182 [41:13<26:35,  1.05it/s]Saving model checkpoint to ../results\\checkpoint-2500\n",
      "Configuration saved in ../results\\checkpoint-2500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0597, 'learning_rate': 4.021999043519848e-06, 'epoch': 1.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../results\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in ../results\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in ../results\\checkpoint-2500\\special_tokens_map.json\n",
      " 62%|██████▏   | 2600/4182 [42:50<24:59,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0792, 'learning_rate': 3.782879005260641e-06, 'epoch': 1.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 2700/4182 [44:25<23:25,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.098, 'learning_rate': 3.543758967001435e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2788/4182 [45:48<22:00,  1.06it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tweet.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2479\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.8979427188382412}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9049523869649683}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.8979427188382412}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9011146780464666}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                   \n",
      " 67%|██████▋   | 2788/4182 [46:35<22:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.054342269897461, 'eval_accuracy': {'accuracy': 0.8979427188382412}, 'eval_precision': {'precision': 0.9049523869649683}, 'eval_recall': {'recall': 0.8979427188382412}, 'eval_f1': {'f1': 0.9011146780464666}, 'eval_runtime': 47.1901, 'eval_samples_per_second': 52.532, 'eval_steps_per_second': 3.285, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2800/4182 [46:47<28:18,  1.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.114, 'learning_rate': 3.3046389287422286e-06, 'epoch': 2.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 2900/4182 [48:22<20:16,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0473, 'learning_rate': 3.065518890483023e-06, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3000/4182 [49:57<18:40,  1.05it/s]Saving model checkpoint to ../results\\checkpoint-3000\n",
      "Configuration saved in ../results\\checkpoint-3000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0712, 'learning_rate': 2.826398852223817e-06, 'epoch': 2.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../results\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in ../results\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in ../results\\checkpoint-3000\\special_tokens_map.json\n",
      " 74%|███████▍  | 3100/4182 [51:33<17:04,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0455, 'learning_rate': 2.5872788139646103e-06, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3200/4182 [53:08<15:31,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0567, 'learning_rate': 2.3481587757054043e-06, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 3300/4182 [54:43<13:59,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0574, 'learning_rate': 2.109038737446198e-06, 'epoch': 2.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 3400/4182 [56:18<12:20,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0619, 'learning_rate': 1.8699186991869919e-06, 'epoch': 2.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 3500/4182 [57:53<10:45,  1.06it/s]Saving model checkpoint to ../results\\checkpoint-3500\n",
      "Configuration saved in ../results\\checkpoint-3500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0484, 'learning_rate': 1.630798660927786e-06, 'epoch': 2.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../results\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in ../results\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in ../results\\checkpoint-3500\\special_tokens_map.json\n",
      " 86%|████████▌ | 3600/4182 [59:30<09:11,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0466, 'learning_rate': 1.3916786226685797e-06, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 3700/4182 [1:01:04<07:36,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0475, 'learning_rate': 1.1525585844093734e-06, 'epoch': 2.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 3800/4182 [1:02:40<06:44,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.038, 'learning_rate': 9.134385461501674e-07, 'epoch': 2.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 3900/4182 [1:04:14<04:42,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0728, 'learning_rate': 6.743185078909613e-07, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 4000/4182 [1:05:54<03:01,  1.00it/s]Saving model checkpoint to ../results\\checkpoint-4000\n",
      "Configuration saved in ../results\\checkpoint-4000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.08, 'learning_rate': 4.3519846963175517e-07, 'epoch': 2.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../results\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in ../results\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in ../results\\checkpoint-4000\\special_tokens_map.json\n",
      " 98%|█████████▊| 4100/4182 [1:07:36<01:22,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0559, 'learning_rate': 1.9607843137254904e-07, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4182/4182 [1:08:04<00:00,  3.59it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tweet.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2479\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9043969342476805}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9043381041566014}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9043969342476805}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9043609053663563}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                     \n",
      "100%|██████████| 4182/4182 [1:08:22<00:00,  3.59it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 4182/4182 [1:08:22<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1118172407150269, 'eval_accuracy': {'accuracy': 0.9043969342476805}, 'eval_precision': {'precision': 0.9043381041566014}, 'eval_recall': {'recall': 0.9043969342476805}, 'eval_f1': {'f1': 0.9043609053663563}, 'eval_runtime': 17.993, 'eval_samples_per_second': 137.776, 'eval_steps_per_second': 8.614, 'epoch': 3.0}\n",
      "{'train_runtime': 4102.9973, 'train_samples_per_second': 16.308, 'train_steps_per_second': 1.019, 'train_loss': 0.04501018460816826, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4182, training_loss=0.04501018460816826, metrics={'train_runtime': 4102.9973, 'train_samples_per_second': 16.308, 'train_steps_per_second': 1.019, 'train_loss': 0.04501018460816826, 'epoch': 3.0})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../results/last-model\\config.json\n",
      "Model weights saved in ../results/last-model\\pytorch_model.bin\n",
      "tokenizer config file saved in ../results/last-model\\tokenizer_config.json\n",
      "Special tokens file saved in ../results/last-model\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../results/last-model\\\\tokenizer_config.json',\n",
       " '../results/last-model\\\\special_tokens_map.json',\n",
       " '../results/last-model\\\\vocab.txt',\n",
       " '../results/last-model\\\\added_tokens.json',\n",
       " '../results/last-model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"../results/last-model\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tweet.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2479\n",
      "  Batch size = 16\n",
      "100%|██████████| 155/155 [00:24<00:00, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2479, 3) (2479,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(train_test_ds[\"test\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.argmax(predictions.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant for classes\n",
    "classes = (\"hate\",\"offensive\",\"neither\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.44      0.44       141\n",
      "           1       0.94      0.94      0.94      1941\n",
      "           2       0.87      0.88      0.88       397\n",
      "\n",
      "    accuracy                           0.90      2479\n",
      "   macro avg       0.75      0.76      0.75      2479\n",
      "weighted avg       0.90      0.90      0.90      2479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=predictions.label_ids,y_pred = y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "target_names = (\"hate\",\"offensive\",\"neither\")\n",
    "cm = confusion_matrix(y_true=predictions.label_ids,y_pred=y_preds)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cccfd8fa3692e38c9904a15873ca7e5836ef9bf62e6240950a461422140e1b82"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
