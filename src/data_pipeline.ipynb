{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch + HF Transformers\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Data Handeling\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "# Text Cleaning\n",
    "import spacy \n",
    "\n",
    "# OS Utils\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if GPU is enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 13 17:59:31 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 496.13       Driver Version: 496.13       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:25:00.0  On |                  N/A |\n",
      "| 29%   30C    P8    10W / 120W |   1496MiB /  3072MiB |      9%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1964    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      3932    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      6208    C+G   ...\\app-1.0.9004\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A      6820    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      8800    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A      9376    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11236    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11688      C   ...ython\\Python39\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     12068    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     12360    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     13144    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     13784    C+G   ...zpdnekdrzrea0\\Spotify.exe    N/A      |\n",
      "|    0   N/A  N/A     14076    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     15216    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     17384    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1060 3GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load local Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"../data/labeled_data.csv\") #load local data stored as csv\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df) # convert pandas dataframe into Huggingface dataset for later use of the Trainer() API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTITY IDS =  ('ws', 'ment', 'url')\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") #using the small english component since it has good performance and is very quick\n",
    "ruler = nlp.add_pipe(\"entity_ruler\",config = {\"overwrite_ents\": True}) # Add an EnitiyRuler Component to the Pipeline and overwrite predefined Ents so only the below specified patterns are recognized\n",
    "\n",
    "# general structure of a spacy pattern is {label:LABEL_NAME, pattern = [{pattern_type:pattern_string},{},...{}] list of subpatterns, id:ID_STRING } \n",
    "patterns = [\n",
    "                {\"label\": \"[URL]\", \"pattern\": [{\"TEXT\":{\"REGEX\":'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'}}], \"id\":\"url\"}, # url pattern\n",
    "                {\"label\": \"[MENTION]\", \"pattern\": [ {\"TEXT\":{\"REGEX\":\"@[\\w\\-]+\"}}], \"id\":\"ment\"}, #twitter mentions pattern\n",
    "                {\"label\": \"[WHITESPACE]\", \"pattern\": [ {\"TEXT\":{\"REGEX\":\"\\s+\"}}], \"id\":\"ws\"} # whitespace pattern\n",
    "            ]\n",
    "\n",
    "ruler.add_patterns(patterns) # add the above defined patterns to ruler-object \n",
    "print(\"ENTITY IDS = \",ruler.ent_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(text_string:str) -> str: \n",
    "    # This method handles the entire string preprocessing \n",
    "    doc = nlp(text_string) # runs the spacy pipeline over the input-string and returning a doc object which incorperates a tokenization, postagging, lemmatization and the regex as entities via the EntityRuler component\n",
    "    out_string = \"\" \n",
    "    for token in doc: \n",
    "        if token.ent_id_ == \"\": # is the token an entitiy of Null-Type (thus not a url,a mention or whitespace) then lemmatize it \n",
    "            out_string = out_string + \" \" + token.lemma_\n",
    "        else:\n",
    "            if token.ent_id_ == \"ws\": # is the token just whitespace then forget the token (we don't want uneccesary whitespace)\n",
    "                pass\n",
    "            else: # otherwise the token has to be a mention or a url so just append the name of the entity-type (to normalize them for the subword tokenizer)\n",
    "                out_string = out_string + \" \" + token.ent_type_\n",
    "    return out_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_STR:\n",
      " this is a beautiful teststring                               hey @yourlocaltwitteruser \n",
      "look at all this whitespace, i hate it, can you please google how to remove it? Use https://www.google.de \n",
      "\n",
      "\n",
      "PROCESSED:\n",
      "  this be a beautiful teststring hey [MENTION] look at all this whitespace , I hate it , can you please google how to remove it ? use [URL]\n"
     ]
    }
   ],
   "source": [
    "test_str = \"\"\"this is a beautiful teststring                               hey @yourlocaltwitteruser \n",
    "look at all this whitespace, i hate it, can you please google how to remove it? Use https://www.google.de \"\"\"\n",
    "\n",
    "print(\"TEST_STR:\\n\",test_str)\n",
    "print(\"\\n\")\n",
    "print(\"PROCESSED:\\n\",preprocess_tweet(test_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased') #load correct tokenizer for uncased distilbert\n",
    "tokenizer.add_tokens([\"[URL]\",\"[MENTION]\"])\n",
    "\n",
    "MAX_SEQ_LEN = 128 # tweets are rarely over 128 tokens long\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token) # adding padding\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token) # adding UNKNOWN-token for out of vocabulary situations\n",
    "\n",
    "def preprocess_function(data:list):\n",
    "    #wrapper for the preprocessing of tweets to work with the datatypes that dataset.map(function) expects\n",
    "    processed_tweets = [preprocess_tweet(tweet) for tweet in data[\"tweet\"]] # preprocess all tweets in the data\n",
    "    return tokenizer(processed_tweets,padding = \"max_length\",max_length=128,truncation=True) #returns tokenized version of processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [03:01<00:00,  7.28s/ba]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function,batched = True) # applying the map method allows for very quick batched processing of text data\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"class\",\"labels\") # Huggingface Trainier expects naming conventions thus rename everything accordingly\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"hate_speech\",\"offensive_language\",\"neither\",\"count\",\"Unnamed: 0\"]) # remove unneccessary columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'tweet', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 24783\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'tweet', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 22304\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'tweet', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 2479\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_test_ds = tokenized_dataset.train_test_split(test_size=0.1) # split in train test sets with test_size = 10%\n",
    "print(train_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists ,overwriting file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 23/23 [00:05<00:00,  3.96ba/s]\n",
      "Flattening the indices: 100%|██████████| 3/3 [00:00<00:00,  4.95ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT WORKING DIR =  c:\\Users\\MEGAPORT\\Documents\\Uni\\WiSe2021_22\\ProjektSeminar\\Project\\H8-Detect\\src\n",
      "File saved at c:\\Users\\MEGAPORT\\Documents\\Uni\\WiSe2021_22\\ProjektSeminar\\Project\\H8-Detect\\data\\processed_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../data/token\\\\tokenizer_config.json',\n",
       " '../data/token\\\\special_tokens_map.json',\n",
       " '../data/token\\\\vocab.txt',\n",
       " '../data/token\\\\added_tokens.json',\n",
       " '../data/token\\\\tokenizer.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r\"../data/processed_data\"\n",
    "\n",
    "if os.path.isdir(data_path):\n",
    "    print(\"File already exists ,overwriting file...\")\n",
    "\n",
    "    os.chdir(r\"../data\") # change directory to rename subdirectory\n",
    "    os.rename(\"processed_data\",\"garbage\") # rename directory to aviod writing conflicts\n",
    "    os.chdir(r\"../src\") # return to previous working directory\n",
    "    shutil.rmtree(r\"../data/garbage\")\n",
    "    # this is neccesary since the huggingface method has no way of overwriting the given directory which will lead to OSError22\n",
    "    train_test_ds.save_to_disk(r\"../data/processed_data\")\n",
    "    print(\"CURRENT WORKING DIR = \", os.getcwd())\n",
    "    print(\"File saved at \" + os.path.abspath(data_path))\n",
    "else:\n",
    "    train_test_ds.save_to_disk(r\"../data/processed_data\")\n",
    "    print(\"CURRENT WORKING DIR = \", os.getcwd())\n",
    "    print(\"File saved at \" + os.path.abspath(data_path))\n",
    "\n",
    "\n",
    "tokenizer.save_pretrained(r\"../data/token\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cccfd8fa3692e38c9904a15873ca7e5836ef9bf62e6240950a461422140e1b82"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
